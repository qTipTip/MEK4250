\documentclass[twocolumn, article]{memoir}

\setlength{\parindent}{0em}
\setlength{\parskip}{0.5cm plus4mm minus3mm}
\usepackage[]{times} 
\usepackage[]{newtxmath} 

\usepackage[]{amsmath} 
\usepackage[]{amssymb} 
\usepackage[]{mathtools} 

\usepackage[]{enumitem} 
\usepackage[]{booktabs} 
\usepackage[]{subcaption} 

\usepackage[]{microtype} 

\usepackage[]{hyperref} 
\usepackage[capitalize, noabbrev]{cleveref} 

\title{\textsc{Mandatory assignment \\ Finite Element Method in Computational
Mechanics \\ MEK4250}}
\author{Ivar Stangeby}
\begin{document}
\maketitle

\chapter*{Exercise 7.2: Stokes problem}

\subsection{Problem statement and strong formulation}    

Let the fluid domain \(\Omega\) be bounded in \(\mathbb{R}^n\) with a
smooth boundary. Denote by \( u \colon \Omega \to \mathbb{R} ^n \) the
fluid velocity, and by \( p \colon \Omega \to \mathbb{R} \) the fluid
pressure. Furthermore, assume that the domain boundary \( \partial\Omega \)
is partitioned into the Dirichlet boundary, and the Neumann boundary,
denoted by \( \partial\Omega_D \) and \( \partial\Omega_N \), respectively.
In its strong form, the Stokes problem reads
\begin{align*}
    -\Delta u + \nabla p &= f, & &\text{in}\quad \Omega;\\
    \nabla \cdot u &= 0, & &\text{in}\quad \Omega;\\
    u &= g, & &\text{on} \quad \partial \Omega_D;\\
    \frac{\partial u}{\partial n} - pn &= h,& &\text{on} \quad \partial\Omega_N.
\end{align*}

\subsection{Well posedness}
\label{sec:well_posedness}

We wish to show the well posedness of the weak formulation of Stokes problem.
In our case, we deal with the sobolev space \( H^1_0(\Omega) \) for the fluid \( u \),
and the \( L^2(\Omega) \) space for the pressure \( p \).  This, involves showing that
the following conditions are met:
\begin{enumerate}[wide, label=\roman*)]
    \item \begin{equation*}
            a(u, v) \leq C_1 \|u\|_{H^1} \|v\|_{L^2},
    \end{equation*}
    \item \begin{equation*}
            b(p, v) \leq C_2 \|p\|_{L^2} \|v\|_{H^1},
    \end{equation*}
    \item \begin{equation*}
            a(u, u) \geq C_3 \|u\|_{H^1}^2,
    \end{equation*}
\end{enumerate}
for all \( u, v \in H^1_0(\Omega) \) and all \( p \in L^2 \).
Recall that the bilinear forms in question are given by
\begin{align*}
    a(u, v) &= \int_\Omega \nabla u : \nabla v \, \mathrm{d}x,\\
    b(p, v) &= \int_\Omega p \nabla \cdot v \, \mathrm{d}x
\end{align*}
where \( \boldsymbol{A} : \boldsymbol{B} = \sum_{i,j} A_{ij}B_{ij} \) denotes
the Frobenius inner product.

\begin{enumerate}[wide, label=\roman*)]
    \item Applying the Cauchy-Schwartz inequality on \( a \) yields the following:
\begin{align*}
    a(u, v) &= \int_\Omega \nabla u : \nabla v \, \mathrm{d}x \\
            &= \langle \nabla u \mid \nabla v \rangle \leq |u|_{H^1}|v|_{H^1}.
\end{align*}
Noting that the seminorm on \( H^1_0 \)is never larger than the full norm on \(
H^1_0\), so the condition holds. 
\item Applying Cauchy-Schwartz on \( b \) yields
\begin{equation*}
    b(p, v) \leq \| p \|_{L^2} \| \nabla \cdot v\|_{L^2}.
\end{equation*}
To this end, it suffices to show that \( \|\nabla \cdot v \|_{L^2} \leq \| v
\|_{H^1} \). For the left hand side, we have that
\begin{equation*}
    \|\nabla \cdot v \|_{L^2} \leq \left( \int_\Omega \sum^{n}_{i=1} \left( \frac{\partial v_i}{\partial x_i} \right)^2 \right)^{1/2}.
\end{equation*}
For the right hand side, firstly we have that
\((\nabla v)^2 = \sum^{n}_{i=1} \sum^{n}_{j=1} \left( \partial v_j / \partial
x_i\right)^2 \). Note that this has a striking resemblance to \( \nabla \cdot v
\), however, with a lot more positive terms. We can therefore conclude outright that
\begin{equation*}
    b(p, v) \leq \|p\|_{L^2}\|v\|_{H^1}.
\end{equation*}
\item Finally, we consider \(a(u, u)\). Firstly, we have that \(\| u \|_{H^1}^2 = \|u
\|_{L^2}^2 + |u|_{H_1}^2\). By applying Poincar\'e, we know that this has to be
less than or equal to \((C^2 + 1)|u|_{H^1}^2\). Writing this out, we have that
\begin{equation*}
    \|u\|^2_{H^1} \leq (C^2 + 1)\int_\Omega (\nabla u)^2 \, \mathrm{d}x.
\end{equation*}
Note that \( (\nabla u)^2 = \nabla u : \nabla u \). Indeed, 
\begin{equation*}
    (\nabla u)^2 = \sum_{j=1}^n \sum_{i=1}^n \left(\frac{\partial u_i}{\partial x_j}\right)^2
    \, = \nabla u : \nabla u.
\end{equation*}
Consequently, we have that \(\|u\|^2_{H^1} \leq (C^2 + 1) a(u, u)\).
Multiplying each side of the equation by \(D \coloneqq 1 / (C^2 + 1)\) we get
the bound we wanted.
\end{enumerate}

\chapter*{Exercise 7.6: Approximation order in Stokes problem}
\label{cha:exercise_7_6_approximation_order_in_poiseuille_flow}

In this exercise we solve Stokes problem as above, with the known solutions:
\begin{align*}
    u &= (\sin(\pi y), \cos(\pi x)), \\
    p &= -\sin(2 \pi x).
\end{align*}
It then follows that the source term is given as:
\begin{equation}
    \notag
    f(x) = (\pi^2 \sin(\pi y) - 2 \pi \cos(2 \pi x), \pi^2 \cos(\pi x)).
\end{equation}
Ideally, we obtain optimal convergence rate, given by
\begin{equation}
    \notag
    \|u - u_h\|_{H^1} + \| p - p_h\|_{L^2} \leq Ch^k\|u\|_{H^{k+1}} + Dh^{\ell + 1} \| p \|_{H^{\ell + 1}},
\end{equation}
where \( k \) and \( \ell \) are the polynomial degree of the velocity and
pressure.  In order to obtain this optimal convergence, we need to determine
the finite element pairs \( V_h \) and \( Q_h\) for the velocity and pressure,
respectively, that satisfy the Babuska--Brezzi condition:
\begin{equation}
    \label{eq:bb_cond}
    \sup_{v_h \in V_{h, g}} \frac{(p_h, \nabla \cdot v_h)}{\|v_h\|_{H^1}} \geq \beta
    \|p_h\|_{L^{2}} > 0, 
\end{equation}
for all \(p_h \in Q_h\).
Elements satisfying \cref{eq:bb_cond} include the following:
\begin{description}
    \item[Taylor-Hood:]
        Quadratic for velocity, and linear for the pressure.
    \item[Crouzeix-Raviart:]
        Linear in velocity, constant in pressure.
    \item[Mini element:]
        Linear in both velocity and pressure, and a cubic bubble function is
        added to the velocity element in order to satisfy \cref{eq:bb_cond}.
\end{description}

In this exercise, we wish to examine whether the approximation is of the
expected order for the \(P_4\) -- \(P_3\), \(P_4\)--\(P_2\), \(P_3\) --
\(P_2\), and \(P_3\) -- \(P_1\) elements. We examine these in turn.  If the
convergence is optimal, we would expect the following:
\begin{description}[wide]
    \item[\(P_4\)--\(P_3\):] 
    With \( k = 4 \) and \(\ell = 3\), we would expect the error to run as \(
    \mathcal{O}(h^4) \).

    \item[\(P_4\)--\(P_2\):]
    With \( k = 4 \) and \(\ell = 2\), we would expect the error to run as \(
    \mathcal{O}(h^3) \).

    \item[\(P_3\)--\(P_2\):]
    With \( k = 3 \) and \(\ell = 2\), we would expect the error to run as \(
    \mathcal{O}(h^3) \).

    \item[\(P_3\)--\(P_1\):]
    With \( k = 3 \) and \(\ell = 2\), we would expect the error to run as \(
    \mathcal{O}(h^2) \).
\end{description}
This is verified by computations, as can be seen in
\cref{tab:approximation_order_7_6}. The convergence rate of the error is given as \( \alpha \), and the error constant is \( C \) in the error estimate \[ \| u - u_h\|_{H^1} + \| p - p_h \|_{L^2} \leq Ch^\alpha.\] These were computed using a linear polynomial fit of the computed errors as \( h \) decrease. The convergence rates seem to agree with predictions. The source code is located in
\texttt{src/exercise\_7\_6.py}.

\begin{table}[tpb]
    \centering
    \caption{Convergence rate and constant for the numerical error in Stokes
    problem.}
    \label{tab:approximation_order_7_6}
    \begin{tabular}{lcc}
    \toprule
    {Element} & \( \alpha \) & \(C\) \\
    \midrule
    \(P_4\) -- \(P_3\) &          4.04615 &    0.344373 \\
    \(P_4\) -- \(P_2\) &          2.92402 &     1.47968 \\
    \(P_3\) -- \(P_2\) &          2.91623 &      1.3616 \\
    \(P_3\) -- \(P_1\) &          2.02219 &     2.26125 \\
    \bottomrule
    \end{tabular}
\end{table}

\chapter*{Linear Elasticity}
\label{cha:linear_elasticity}

In this exercise, we examine whether the phenomenon known as ``locking'' occurs
when solving a specfic linear elasticity problem. We restrict our attention to
the unit rectangle domain, i.e., we let \( \Omega \coloneqq (0, 1)^2\), and
consider the following problem:
\begin{align*}
    - \mu \Delta u - \lambda\nabla\nabla \cdot u &= f & & \text{in } \Omega; \\
    u &= \hat{u}& & \text{on } \partial\Omega.
\end{align*}
We consider only the known problem where we let 
\begin{equation}
    \notag
    \hat{u}\coloneqq \Big( \frac{\partial \varphi}{\partial y}, -\frac{\partial
    \varphi}{\partial x} \Big), 
\end{equation}
and \( \varphi \coloneqq \sin(\pi x y) \). By construction, we have that
\(\nabla \cdot \hat{u}= 0 \). Furthermore, 
\begin{equation}
    \notag
    \hat{u} = \left( \pi x \cos(\pi x y), -\pi y\cos(\pi x y) \right),
\end{equation}
and inserting this into the expression for \( f \) yields
\begin{equation}
    \notag
    f = -\mu \Delta \hat{u} - \lambda \nabla \overbrace{(\nabla \cdot
    \hat{u})}^{0 \text{ on } \partial\Omega} = -\mu \nabla \cdot \nabla
    \hat{u}. 
\end{equation}
Solving this results in 
\begin{align*}
    f = \mu \Big[ \pi^2\left(\pi x ( x^2 + y^2)\cos(\pi x y) + 2 y \sin(\pi x y)\right), \\
        -\pi^2 \left(\pi y (x^2 + y^2) \cos(\pi x y) + 2 x \sin( \pi x y)\right) \Big].
\end{align*}

\subsection*{Error analysis}

For simplicity, we set \( \mu = 1 \) as we want to examine the behaviour when
\(\lambda \gg \mu\) .  We wish to run the simulations for the parameters \(
\lambda = 1, 10, 100, 1000 \), for varying number of elements, \( N = 8, 16,
32, 64 \). We do this for both first and second order elements. In addition, we
compute the order of convergence \( \alpha \) for the different choices of \(
\lambda \). As we see from the results in
\cref{tab:first_order_error,tab:second_order_error}, something happens as
\(\lambda\) increases.

\begin{table}[tbp]
    \centering
    \caption{The \(L^2\) error for first order elements.}
    \label{tab:first_order_error}
    \begin{tabular}{lcccc}
    \toprule
    {\(N\)} &      \( \lambda = 1\)    &      \(\lambda = 10\)   &      \( \lambda = 100\)  &      \( \lambda = 1000\) \\
    \midrule
    8  &  0.071458 &  0.112468 &  0.299871 &  0.423944 \\
    16 &  0.018590 &  0.034623 &  0.164068 &  0.382477 \\
    32 &  0.004697 &  0.009287 &  0.060761 &  0.260852 \\
    64 &  0.001177 &  0.002368 &  0.017654 &  0.121142 \\
    \bottomrule
    \end{tabular}
\end{table}

\begin{table}[tpb]
    \centering
    \caption{The \(L^2\) error for second order elements.}
    \label{tab:second_order_error}
    \begin{tabular}{lcccc}
    \toprule
    {\(N\)} &      \( \lambda = 1\)    &      \(\lambda = 10\)   &      \( \lambda = 100\)  &      \( \lambda = 1000\) \\
    \midrule
    8  &  0.002081 &  0.003511 &  0.014397 &  0.026995 \\
    16 &  0.000252 &  0.000324 &  0.001498 &  0.005144 \\
    32 &  0.000031 &  0.000034 &  0.000119 &  0.000690 \\
    64 &  0.000004 &  0.000004 &  0.000009 &  0.000064 \\
    \bottomrule
    \end{tabular}
\end{table}

\begin{table}[htpb]
    \centering
    \caption{The convergence rates \( \alpha \) for various values of
    \(\lambda\), for first and second order elements.}
    \label{tab:convergence}

    \begin{minipage}{.4\linewidth}
    \subcaption{\(P_1\)}
    \begin{tabular}{lc}
    \toprule
    {\(\lambda\)} & \(\alpha\) \\
    \midrule
    1    &  1.975469 \\
    10   &  1.860708 \\
    100  &  1.369199 \\
    1000 &  0.597364 \\
    \bottomrule
    \end{tabular}
    \end{minipage}%
    \begin{minipage}{.4\linewidth}
    \subcaption{\(P_2\)}
        \begin{tabular}{lc}
        \toprule
        {\(N\)} &     \(\alpha\) \\
        \midrule
        1    &  3.019544 \\
        10   &  3.259812 \\
        100  &  3.570450 \\
        1000 &  2.907964 \\
        \bottomrule
        \end{tabular}
    \end{minipage}
\end{table}
This fact is more easily seen by examining the convergence rates, as shown in
\cref{tab:convergence}. It is evident that locking does occur. The source code
can be found in \texttt{src/linear\_elasticity.py}.

\end{document}
